getting started:
https://github.com/meta-llama/llama-stack/blob/main/docs/getting_started.md

commands:
https://github.com/meta-llama/llama-stack/blob/main/docs/cli_reference.md

configurations:
To be explained at later time when finalized

Run command:
llama stack run 3.1-8B-Instruct-GPU --port 5000

llama stack client used to interact with the server:
from llama_stack_client

Configuring API `agents`...
> Configuring provider `(meta-reference)`
Enter `type` for persistence_store (options: redis, sqlite, postgres) (default: sqlite): postgres

Configuring PostgresKVStoreConfig:
Enter value for namespace (optional): agents_data
Enter value for host (default: localhost) (required): localhost
Enter value for port (default: 5432) (required): 2222
Enter value for db (default: llamastack) (required): llamastack
Enter value for user (required): postgres
Enter value for password (optional): 

chromadb run:
chroma run --host localhost --port 8000