{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references\n",
    "https://python.langchain.com/docs/integrations/llms/ollama/\n",
    "\n",
    "https://api.python.langchain.com/en/latest/graph_transformers/langchain_experimental.graph_transformers.llm.LLMGraphTransformer.html\n",
    "\n",
    "https://python.langchain.com/docs/how_to/document_loader_json/\n",
    "https://thesai.org/Downloads/Volume10No10/Paper_30-JsonToOnto_Building_Owl2_Ontologies.pdf\n",
    "\n",
    "owl to neo4j to graphRAG\n",
    "https://neo4j.com/blog/using-owl-with-neo4j/?utm_source=GSearch&utm_medium=PaidSearch&utm_campaign=Evergreen&utm_content=AMS-Search-SEMCE-DSA-None-SEM-SEM-NonABM&utm_term=&utm_adgroup=DSA&gad_source=1&gclid=CjwKCAiAudG5BhAREiwAWMlSjFNimXejezc7i1kEQlYU_gi_es4y2GsJU0q_egaOoWvEB3w8YzP3SRoC-mAQAvD_BwE\n",
    "\n",
    "https://neo4j.com/labs/neosemantics/4.0/importing-ontologies/\n",
    "\n",
    "https://neo4j.com/developer-blog/neo4j-graphrag-workflow-langchain-langgraph/\n",
    "\n",
    "they used microsoft graphRAG\n",
    "https://medium.com/@ianormy/microsoft-graphrag-with-an-rdf-knowledge-graph-part-1-00a354afdb09\n",
    "\n",
    "\n",
    "systemctl {start|stop|restart} neo4j\n",
    "\n",
    "neo4j=1.5.25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from langchain.chains import GraphQAChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"Sakul32524!\"\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model = \"llama3.1:8b-instruct-fp16\") \n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\" \n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    Neural network model consisting of layers propsed by AlexNet paper.\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        \n",
    "        Define and allocate layers for this neural net.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): number of classes to predict with this model\n",
    "        \n",
    "        super().__init__()\n",
    "        # input size should be : (b x 3 x 227 x 227)\n",
    "        # The image in the original paper states that width and height are 224 pixels, but\n",
    "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
    "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
    "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
    "        )\n",
    "        # classifier is just a name for linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes),\n",
    "        )\n",
    "        self.init_bias()  # initialize bias \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='num_classes', type='Parameter', properties={}), Node(id='num_classes=1000', type='Parameter', properties={}), Node(id='number of classes to predict with this model', type='Definition', properties={}), Node(id='Neural network model', type='Definition', properties={}), Node(id='layers proposed by AlexNet paper', type='Paper', properties={}), Node(id='(b x 3 x 227 x 227)', type='Input Size', properties={}), Node(id='AlexNet', type='Model', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='AlexNet', type='Model', properties={}), target=Node(id='layers proposed by AlexNet paper', type='Paper', properties={}), type='CONSISTS_OF', properties={}), Relationship(source=Node(id='AlexNet', type='Model', properties={}), target=Node(id='Neural network model', type='Definition', properties={}), type='DEFINITION', properties={}), Relationship(source=Node(id='AlexNet', type='Model', properties={}), target=Node(id='num_classes=1000', type='Parameter', properties={}), type='PARAMETERIZED_BY', properties={}), Relationship(source=Node(id='num_classes=1000', type='Parameter', properties={}), target=Node(id='number of classes to predict with this model', type='Definition', properties={}), type='DEFINITION', properties={}), Relationship(source=Node(id='AlexNet', type='Model', properties={}), target=Node(id='num_classes', type='Parameter', properties={}), type='PARAMETERIZED_BY', properties={}), Relationship(source=Node(id='AlexNet', type='Model', properties={}), target=Node(id='(b x 3 x 227 x 227)', type='Input Size', properties={}), type='INPUT_SIZE', properties={})]\n"
     ]
    }
   ],
   "source": [
    "documents = [Document(page_content=text)]\n",
    "llm_transformer = LLMGraphTransformer(llm=llm, strict_mode=True)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes = network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='layers propsed by AlexNet paper', type='Layers', properties={}), Node(id='AlexNet', type='Model', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='AlexNet', type='Model', properties={}), target=Node(id='layers propsed by AlexNet paper', type='Layers', properties={}), type='CONSISTS_OF', properties={})]\n"
     ]
    }
   ],
   "source": [
    "llm_transformer_filtered = LLMGraphTransformer(\n",
    "    llm = llm,\n",
    "    allowed_nodes =[\"Classes\", \"\", \"Parameters\"],\n",
    "    # allowed_relationships=[\"\"]\n",
    ")\n",
    "graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt: str) -> str:\n",
    "    response = llm.chat(messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_qa_chain = GraphQAChain(\n",
    "    graph=NetworkxEntityGraph(graph),\n",
    "    llm=query_ollama\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "result = graph_qa_chain.run(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
