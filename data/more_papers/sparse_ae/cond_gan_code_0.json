[
   {
      "page_content": "",
      "metadata": {
         "section_header": "Global Variables",
         "type": "python global"
      }
   },
   {
      "page_content": "import torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nclass UNetDown(nn.Module):\n\tdef __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n\t\tsuper(UNetDown, self).__init__()\n\t\tmodel = [nn.Conv2d(in_size, out_size, 4, stride=2, padding=1, bias=False)]\n\t\tif normalize:\n\t\t\tmodel.append(nn.BatchNorm2d(out_size, 0.8))\n\t\tmodel.append(nn.LeakyReLU(0.2))\n\t\tif dropout:\n\t\t\tmodel.append(nn.Dropout(dropout))\n\t\tself.model = nn.Sequential(*model)\n\tdef forward(self, x):\n\t\treturn self.model(x)\nclass UNetUp(nn.Module):\n\tdef __init__(self, in_size, out_size, dropout=0.0):\n\t\tsuper(UNetUp, self).__init__()\n\t\tmodel = [\n\t\t\tnn.ConvTranspose2d(in_size, out_size, 4, stride=2, padding=1, bias=False),\n\t\t\tnn.BatchNorm2d(out_size, 0.8),\n\t\t\tnn.ReLU(inplace=True),\n\t\t]\n\t\tif dropout:\n\t\t\tmodel.append(nn.Dropout(dropout))\n\t\tself.model = nn.Sequential(*model)\n\tdef forward(self, x, skip_input):\n\t\tx = self.model(x)\n\t\tout = torch.cat((x, skip_input), 1)\n\t\treturn out\nclass Generator(nn.Module):\n\tdef __init__(self, input_shape):\n\t\tsuper(Generator, self).__init__()\n\t\tchannels, _, _ = input_shape\n\t\tself.down1 = UNetDown(channels, 64, normalize=False)\n\t\tself.down2 = UNetDown(64, 128)\n\t\tself.down3 = UNetDown(128 + channels, 256, dropout=0.5)\n\t\tself.down4 = UNetDown(256, 512, dropout=0.5)\n\t\tself.down5 = UNetDown(512, 512, dropout=0.5)\n\t\tself.down6 = UNetDown(512, 512, dropout=0.5)\n\t\tself.up1 = UNetUp(512, 512, dropout=0.5)\n\t\tself.up2 = UNetUp(1024, 512, dropout=0.5)\n\t\tself.up3 = UNetUp(1024, 256, dropout=0.5)\n\t\tself.up4 = UNetUp(512, 128)\n\t\tself.up5 = UNetUp(256 + channels, 64)\n\t\tfinal = [nn.Upsample(scale_factor=2), nn.Conv2d(128, channels, 3, 1, 1), nn.Tanh()]\n\t\tself.final = nn.Sequential(*final)\n\tdef forward(self, x, x_lr):\n\t\t# U-Net generator with skip connections from encoder to decoder\n\t\td1 = self.down1(x)\n\t\td2 = self.down2(d1)\n\t\td2 = torch.cat((d2, x_lr), 1)\n\t\td3 = self.down3(d2)\n\t\td4 = self.down4(d3)\n\t\td5 = self.down5(d4)\n\t\td6 = self.down6(d5)\n\t\tu1 = self.up1(d6, d5)\n\t\tu2 = self.up2(u1, d4)\n\t\tu3 = self.up3(u2, d3)\n\t\tu4 = self.up4(u3, d2)\n\t\tu5 = self.up5(u4, d1)\n\t\treturn self.final(u5)\nclass Discriminator(nn.Module):\n\tdef __init__(self, input_shape):\n\t\tsuper(Discriminator, self).__init__()\n\t\tchannels, height, width = input_shape\n\t\t# Calculate output of image discriminator (PatchGAN)\n\t\tpatch_h, patch_w = int(height / 2 ** 3), int(width / 2 ** 3)\n\t\tself.output_shape = (1, patch_h, patch_w)\n\t\tdef discriminator_block(in_filters, out_filters, stride, normalize):\n\t\t\t\"\"\"Returns layers of each discriminator block\"\"\"\n\t\t\tlayers = [nn.Conv2d(in_filters, out_filters, 3, stride, 1)]\n\t\t\tif normalize:\n\t\t\t\tlayers.append(nn.InstanceNorm2d(out_filters))\n\t\t\tlayers.append(nn.LeakyReLU(0.2, inplace=True))\n\t\t\treturn layers\n\t\tlayers = []\n\t\tin_filters = channels\n\t\tfor out_filters, stride, normalize in [(64, 2, False), (128, 2, True), (256, 2, True), (512, 1, True)]:\n\t\t\tlayers.extend(discriminator_block(in_filters, out_filters, stride, normalize))\n\t\t\tin_filters = out_filters\n\t\tlayers.append(nn.Conv2d(out_filters, 1, 3, 1, 1))\n\t\tself.model = nn.Sequential(*layers)\n\tdef forward(self, img):\n\t\treturn self.model(img)",
      "metadata": {
         "section_header": "Global Other",
         "type": "python global"
      }
   },
   {
      "page_content": "Functions: __init__, forward",
      "metadata": {
         "section_header": "UNetDown",
         "type": "python class"
      }
   },
   {
      "page_content": "\tdef __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n\t\tsuper(UNetDown, self).__init__()\n\t\tmodel = [nn.Conv2d(in_size, out_size, 4, stride=2, padding=1, bias=False)]\n\t\tif normalize:\n\t\t\tmodel.append(nn.BatchNorm2d(out_size, 0.8))\n\t\tmodel.append(nn.LeakyReLU(0.2))\n\t\tif dropout:\n\t\t\tmodel.append(nn.Dropout(dropout))\n\t\tself.model = nn.Sequential(*model)",
      "metadata": {
         "section_header": "__init__",
         "type": "python function"
      }
   },
   {
      "page_content": "\tdef forward(self, x):\n\t\treturn self.model(x)",
      "metadata": {
         "section_header": "forward",
         "type": "python function"
      }
   },
   {
      "page_content": "Functions: __init__, forward",
      "metadata": {
         "section_header": "UNetUp",
         "type": "python class"
      }
   },
   {
      "page_content": "\tdef __init__(self, in_size, out_size, dropout=0.0):\n\t\tsuper(UNetUp, self).__init__()\n\t\tmodel = [\n\t\t\tnn.ConvTranspose2d(in_size, out_size, 4, stride=2, padding=1, bias=False),\n\t\t\tnn.BatchNorm2d(out_size, 0.8),\n\t\t\tnn.ReLU(inplace=True),\n\t\t]\n\t\tif dropout:\n\t\t\tmodel.append(nn.Dropout(dropout))\n\t\tself.model = nn.Sequential(*model)",
      "metadata": {
         "section_header": "__init__",
         "type": "python function"
      }
   },
   {
      "page_content": "\tdef forward(self, x, skip_input):\n\t\tx = self.model(x)\n\t\tout = torch.cat((x, skip_input), 1)\n\t\treturn out",
      "metadata": {
         "section_header": "forward",
         "type": "python function"
      }
   },
   {
      "page_content": "Functions: __init__, forward",
      "metadata": {
         "section_header": "Generator",
         "type": "python class"
      }
   },
   {
      "page_content": "\tdef __init__(self, input_shape):\n\t\tsuper(Generator, self).__init__()\n\t\tchannels, _, _ = input_shape\n\t\tself.down1 = UNetDown(channels, 64, normalize=False)\n\t\tself.down2 = UNetDown(64, 128)\n\t\tself.down3 = UNetDown(128 + channels, 256, dropout=0.5)\n\t\tself.down4 = UNetDown(256, 512, dropout=0.5)\n\t\tself.down5 = UNetDown(512, 512, dropout=0.5)\n\t\tself.down6 = UNetDown(512, 512, dropout=0.5)\n\t\tself.up1 = UNetUp(512, 512, dropout=0.5)\n\t\tself.up2 = UNetUp(1024, 512, dropout=0.5)\n\t\tself.up3 = UNetUp(1024, 256, dropout=0.5)\n\t\tself.up4 = UNetUp(512, 128)\n\t\tself.up5 = UNetUp(256 + channels, 64)\n\t\tfinal = [nn.Upsample(scale_factor=2), nn.Conv2d(128, channels, 3, 1, 1), nn.Tanh()]\n\t\tself.final = nn.Sequential(*final)",
      "metadata": {
         "section_header": "__init__",
         "type": "python function"
      }
   },
   {
      "page_content": "\tdef forward(self, x, x_lr):\n\t\t# U-Net generator with skip connections from encoder to decoder\n\t\td1 = self.down1(x)\n\t\td2 = self.down2(d1)\n\t\td2 = torch.cat((d2, x_lr), 1)\n\t\td3 = self.down3(d2)\n\t\td4 = self.down4(d3)\n\t\td5 = self.down5(d4)\n\t\td6 = self.down6(d5)\n\t\tu1 = self.up1(d6, d5)\n\t\tu2 = self.up2(u1, d4)\n\t\tu3 = self.up3(u2, d3)\n\t\tu4 = self.up4(u3, d2)\n\t\tu5 = self.up5(u4, d1)\n\t\treturn self.final(u5)",
      "metadata": {
         "section_header": "forward",
         "type": "python function"
      }
   },
   {
      "page_content": "Functions: __init__, forward",
      "metadata": {
         "section_header": "Discriminator",
         "type": "python class"
      }
   },
   {
      "page_content": "\tdef __init__(self, input_shape):\n\t\tsuper(Discriminator, self).__init__()\n\t\tchannels, height, width = input_shape\n\t\t# Calculate output of image discriminator (PatchGAN)\n\t\tpatch_h, patch_w = int(height / 2 ** 3), int(width / 2 ** 3)\n\t\tself.output_shape = (1, patch_h, patch_w)\n\t\tdef discriminator_block(in_filters, out_filters, stride, normalize):\n\t\t\t\"\"\"Returns layers of each discriminator block\"\"\"\n\t\t\tlayers = [nn.Conv2d(in_filters, out_filters, 3, stride, 1)]\n\t\t\tif normalize:\n\t\t\t\tlayers.append(nn.InstanceNorm2d(out_filters))\n\t\t\tlayers.append(nn.LeakyReLU(0.2, inplace=True))\n\t\t\treturn layers\n\t\tlayers = []\n\t\tin_filters = channels\n\t\tfor out_filters, stride, normalize in [(64, 2, False), (128, 2, True), (256, 2, True), (512, 1, True)]:\n\t\t\tlayers.extend(discriminator_block(in_filters, out_filters, stride, normalize))\n\t\t\tin_filters = out_filters\n\t\tlayers.append(nn.Conv2d(out_filters, 1, 3, 1, 1))\n\t\tself.model = nn.Sequential(*layers)",
      "metadata": {
         "section_header": "__init__",
         "type": "python function"
      }
   },
   {
      "page_content": "\tdef forward(self, img):\n\t\treturn self.model(img)",
      "metadata": {
         "section_header": "forward",
         "type": "python function"
      }
   }
]