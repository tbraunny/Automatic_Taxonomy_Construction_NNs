history:

10/18/2024: Lukas - 13 hours
installed requirements on requirements.txt file
downloaded on root, labmates said it was ok. Made sure to make a new user though.
^ fixed the above as downloading in root could corrupt virtual machine

installed:
llama-stack
sudo apt-get install cuda-runtime-12-4
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

10/21/2024: Lukas - 6 hours
Had to reinstall llama-stack and officially got the server working however couldn't configure to ollama.

previous week after 10/21: Lukas - 13
worked with team on building a logistical framework and researching more in depth for tech configurations.

10/30/2024: Lukas -  6 hours
Met with stakeholder(30 minutes) and went to lab after to setup llama stack with ollama inference (rest of the time). Also met up with whole team for usual team discussion. (1 hour)


11/1/2024: Lukas - 7 hours
fully configured llama stack using docker instead as it wouldnt connect with the client

11/5/2024: 
